[{"content":"ipmitool sdr elist 命令用于显示系统传感器的状态信息。\nSEL 和 SDR 是 IPMI（Intelligent Platform Management Interface）中的两个重要概念，它们分别表示系统事件日志和传感器数据记录。\n1. SEL (System Event Log) SEL 代表 System Event Log，即系统事件日志。它是一个记录了系统中关键事件的日志文件，通常包括硬件故障、警告、系统启动和关闭事件等。SEL 通常用于诊断和排除硬件问题。事件日志会记录事件的时间戳、事件类型、严重程度以及相关的详细信息。\n命令示例: 使用 ipmitool 查看 SEL： 1 sudo ipmitool sel list 这个命令会列出所有记录的系统事件，帮助管理员分析系统中的异常情况。 2. SDR (Sensor Data Record) SDR 代表 Sensor Data Record，即传感器数据记录。它是一个存储在系统中的数据库，包含了系统内所有传感器的详细信息，包括传感器的类型、名称、ID、状态、当前值、报警阈值等。SDR 是 IPMI 系统中用于监控和管理硬件状态的核心部分。\n命令示例: 使用 ipmitool 查看 SDR： 1 sudo ipmitool sdr 这个命令会列出系统中所有传感器的状态和读数，允许管理员监控系统的健康状态。 总结： SEL 用于记录和查看系统事件，帮助诊断和排除故障。 SDR 用于存储和管理传感器数据，实时监控系统的各项参数。 了解 SEL 和 SDR 是 IPMI 管理的重要部分，能够帮助你更好地维护和管理服务器的硬件状态。\n输出的每一行代表一个电源模块（PS1、PS2、PS3、PS4）的状态。以下是输出信息的含义：\nPS1 Status:\nC4h: 传感器ID，具体的数值因硬件而异。 ok: 状态正常。 10.92: 电压或类似的数值，这里通常表示与电源相关的数值。 Presence detected: 表示电源模块被检测到存在。 PS2 Status:\nC5h: 传感器ID。 ok: 状态正常。 10.91: 电压或类似的数值。 Presence detected, Failure detected: 表示电源模块被检测到存在，但也检测到故障。 PS3 Status:\nC6h: 传感器ID。 ok: 状态正常。 10.90: 电压或类似的数值。 Presence detected: 表示电源模块被检测到存在。 PS4 Status:\nC7h: 传感器ID。 ok: 状态正常。 10.89: 电压或类似的数值。 Presence detected: 表示电源模块被检测到存在。 关键点： Presence detected: 电源模块被检测到。 Failure detected: 仅在 PS2 中出现，表明这个电源模块存在某种故障。虽然状态显示为 ok，但这可能是因为故障并不影响系统的整体运行，但仍然值得进一步检查。 你可能需要检查 PS2 的具体状态，可能需要通过 ipmitool 获取更多详细信息或查看相关日志，确保电源模块在未来不会引发更严重的问题。\n","permalink":"http://119.91.218.8/zh/posts/1556/","summary":"\u003cp\u003e\u003ccode\u003eipmitool sdr elist\u003c/code\u003e 命令用于显示系统传感器的状态信息。\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eSEL\u003c/code\u003e 和 \u003ccode\u003eSDR\u003c/code\u003e 是 \u003ccode\u003eIPMI\u003c/code\u003e（Intelligent Platform Management Interface）中的两个重要概念，它们分别表示系统事件日志和传感器数据记录。\u003c/p\u003e","title":"电源故障查询指令"},{"content":"今天在尝试复现quip#的时候发现了问题，在进行setup install的时候发现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [1/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /home/ubuntu/data/exp/quip-sharp/quiptools/build/temp.linux-x86_64-cpython-311/quiptools.o.d -I/home/ubuntu/miniconda3/envs/quant/lib/python3.11/site-packages/torch/include -I/home/ubuntu/miniconda3/envs/quant/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/ubuntu/miniconda3/envs/quant/lib/python3.11/site-packages/torch/include/TH -I/home/ubuntu/miniconda3/envs/quant/lib/python3.11/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/ubuntu/miniconda3/envs/quant/include/python3.11 -c -c /home/ubuntu/data/exp/quip-sharp/quiptools/quiptools.cu -o /home/ubuntu/data/exp/quip-sharp/quiptools/build/temp.linux-x86_64-cpython-311/quiptools.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options \u0026#39;\u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;-fPIC\u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;\u0026#39; -O2 -g -Xcompiler -rdynamic -lineinfo -std=c++20 -DTORCH_API_INCLUDE_EXTENSION_H \u0026#39;-DPYBIND11_COMPILER_TYPE=\u0026#34;_gcc\u0026#34;\u0026#39; \u0026#39;-DPYBIND11_STDLIB=\u0026#34;_libstdcpp\u0026#34;\u0026#39; \u0026#39;-DPYBIND11_BUILD_ABI=\u0026#34;_cxxabi1011\u0026#34;\u0026#39; -DTORCH_EXTENSION_NAME=quiptools_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm_89 FAILED: /home/ubuntu/data/exp/quip-sharp/quiptools/build/temp.linux-x86_64-cpython-311/quiptools.o /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /home/ubuntu/data/exp/quip-sharp/quiptools/build/temp.linux-x86_64-cpython-311/quiptools.o.d -I/home/ubuntu/miniconda3/envs/quant/lib/python3.11/site-packages/torch/include -I/home/ubuntu/miniconda3/envs/quant/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/ubuntu/miniconda3/envs/quant/lib/python3.11/site-packages/torch/include/TH -I/home/ubuntu/miniconda3/envs/quant/lib/python3.11/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/ubuntu/miniconda3/envs/quant/include/python3.11 -c -c /home/ubuntu/data/exp/quip-sharp/quiptools/quiptools.cu -o /home/ubuntu/data/exp/quip-sharp/quiptools/build/temp.linux-x86_64-cpython-311/quiptools.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options \u0026#39;\u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;-fPIC\u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;\u0026#39; -O2 -g -Xcompiler -rdynamic -lineinfo -std=c++20 -DTORCH_API_INCLUDE_EXTENSION_H \u0026#39;-DPYBIND11_COMPILER_TYPE=\u0026#34;_gcc\u0026#34;\u0026#39; \u0026#39;-DPYBIND11_STDLIB=\u0026#34;_libstdcpp\u0026#34;\u0026#39; \u0026#39;-DPYBIND11_BUILD_ABI=\u0026#34;_cxxabi1011\u0026#34;\u0026#39; -DTORCH_EXTENSION_NAME=quiptools_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm_89 /usr/include/x86_64-linux-gnu/bits/floatn-common.h(214): error: invalid combination of type specifiers typedef float _Float32; ^ /usr/include/x86_64-linux-gnu/bits/floatn-common.h(251): error: invalid combination of type specifiers typedef double _Float64; 事实上只要清理干净使用的gcc和g++版本\n1 2 3 4 5 6 7 8 9 10 11 12 ls /usr/bin/gcc* ls /usr/bin/g++* sudo apt remove gcc-10 gcc-13 g++-10 g++-13 # 通常ubuntu20.04使用9.4版本的gcc和g++ # 手动创建这些链接 sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 60 sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-9 60 # 设置对应版本 sudo update-alternatives --config gcc sudo update-alternatives --config g++ ","permalink":"http://119.91.218.8/zh/posts/1609/","summary":"\u003cp\u003e今天在尝试复现quip#的时候发现了问题，在进行setup install的时候发现\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e15\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e16\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e17\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e[\u003c/span\u003e1/3\u003cspan class=\"o\"\u003e]\u003c/span\u003e /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /home/ubuntu/data/exp/quip-sharp/quiptools/build/temp.linux-x86_64-cpython-311/quiptools.o.d -I/home/ubuntu/miniconda3/envs/quant/lib/python3.11/site-packages/torch/include -I/home/ubuntu/miniconda3/envs/quant/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/ubuntu/miniconda3/envs/quant/lib/python3.11/site-packages/torch/include/TH -I/home/ubuntu/miniconda3/envs/quant/lib/python3.11/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/ubuntu/miniconda3/envs/quant/include/python3.11 -c -c /home/ubuntu/data/exp/quip-sharp/quiptools/quiptools.cu -o /home/ubuntu/data/exp/quip-sharp/quiptools/build/temp.linux-x86_64-cpython-311/quiptools.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options \u003cspan class=\"s1\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u0026#39;\u0026#34;\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;-fPIC\u0026#39;\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u0026#39;\u0026#34;\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e -O2 -g -Xcompiler -rdynamic -lineinfo -std\u003cspan class=\"o\"\u003e=\u003c/span\u003ec++20 -DTORCH_API_INCLUDE_EXTENSION_H \u003cspan class=\"s1\"\u003e\u0026#39;-DPYBIND11_COMPILER_TYPE=\u0026#34;_gcc\u0026#34;\u0026#39;\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;-DPYBIND11_STDLIB=\u0026#34;_libstdcpp\u0026#34;\u0026#39;\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;-DPYBIND11_BUILD_ABI=\u0026#34;_cxxabi1011\u0026#34;\u0026#39;\u003c/span\u003e -DTORCH_EXTENSION_NAME\u003cspan class=\"o\"\u003e=\u003c/span\u003equiptools_cuda -D_GLIBCXX_USE_CXX11_ABI\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"m\"\u003e0\u003c/span\u003e -gencode\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"nv\"\u003earch\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003ecompute_89,code\u003cspan class=\"o\"\u003e=\u003c/span\u003ecompute_89 -gencode\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"nv\"\u003earch\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003ecompute_89,code\u003cspan class=\"o\"\u003e=\u003c/span\u003esm_89\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eFAILED: /home/ubuntu/data/exp/quip-sharp/quiptools/build/temp.linux-x86_64-cpython-311/quiptools.o\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e/usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /home/ubuntu/data/exp/quip-sharp/quiptools/build/temp.linux-x86_64-cpython-311/quiptools.o.d -I/home/ubuntu/miniconda3/envs/quant/lib/python3.11/site-packages/torch/include -I/home/ubuntu/miniconda3/envs/quant/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/ubuntu/miniconda3/envs/quant/lib/python3.11/site-packages/torch/include/TH -I/home/ubuntu/miniconda3/envs/quant/lib/python3.11/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/ubuntu/miniconda3/envs/quant/include/python3.11 -c -c /home/ubuntu/data/exp/quip-sharp/quiptools/quiptools.cu -o /home/ubuntu/data/exp/quip-sharp/quiptools/build/temp.linux-x86_64-cpython-311/quiptools.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options \u003cspan class=\"s1\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u0026#39;\u0026#34;\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;-fPIC\u0026#39;\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u0026#39;\u0026#34;\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e -O2 -g -Xcompiler -rdynamic -lineinfo -std\u003cspan class=\"o\"\u003e=\u003c/span\u003ec++20 -DTORCH_API_INCLUDE_EXTENSION_H \u003cspan class=\"s1\"\u003e\u0026#39;-DPYBIND11_COMPILER_TYPE=\u0026#34;_gcc\u0026#34;\u0026#39;\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;-DPYBIND11_STDLIB=\u0026#34;_libstdcpp\u0026#34;\u0026#39;\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;-DPYBIND11_BUILD_ABI=\u0026#34;_cxxabi1011\u0026#34;\u0026#39;\u003c/span\u003e -DTORCH_EXTENSION_NAME\u003cspan class=\"o\"\u003e=\u003c/span\u003equiptools_cuda -D_GLIBCXX_USE_CXX11_ABI\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"m\"\u003e0\u003c/span\u003e -gencode\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"nv\"\u003earch\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003ecompute_89,code\u003cspan class=\"o\"\u003e=\u003c/span\u003ecompute_89 -gencode\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"nv\"\u003earch\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003ecompute_89,code\u003cspan class=\"o\"\u003e=\u003c/span\u003esm_89\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e/usr/include/x86_64-linux-gnu/bits/floatn-common.h\u003cspan class=\"o\"\u003e(\u003c/span\u003e214\u003cspan class=\"o\"\u003e)\u003c/span\u003e: error: invalid combination of \u003cspan class=\"nb\"\u003etype\u003c/span\u003e specifiers\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  typedef float _Float32\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                ^\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e/usr/include/x86_64-linux-gnu/bits/floatn-common.h\u003cspan class=\"o\"\u003e(\u003c/span\u003e251\u003cspan class=\"o\"\u003e)\u003c/span\u003e: error: invalid combination of \u003cspan class=\"nb\"\u003etype\u003c/span\u003e specifiers\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  typedef double _Float64\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e事实上只要清理干净使用的gcc和g++版本\u003c/p\u003e","title":"记录一次编译pytorch 的cuda插件的踩坑过程"},{"content":"丢弃更改 1. 丢弃工作区的未暂存更改 如果你在工作区修改了文件但尚未暂存（使用 git add），可以使用以下命令将文件恢复到上一次提交时的状态：\n1 git checkout -- \u0026lt;file\u0026gt; 这个命令会丢弃指定文件的更改，恢复到上次提交的版本。\n如果想丢弃所有文件的更改，可以使用：\n1 git checkout -- . 2. 丢弃已暂存的更改 如果你已经使用 git add 将更改暂存，但还没有提交，可以使用以下命令将更改从暂存区移除，但保留在工作区中：\n1 git reset HEAD \u0026lt;file\u0026gt; 这样做会将文件从暂存区移除，但工作区中的更改仍然存在。\n如果想将所有已暂存的文件移除暂存区，可以使用：\n1 git reset HEAD . 3. 丢弃所有未提交的更改（包括工作区和暂存区） 如果你想要彻底丢弃所有未提交的更改（包括工作区和暂存区的更改），可以使用以下命令：\n1 git reset --hard 这个命令会将你的工作区和暂存区重置到上一次提交的状态，所有未提交的更改都会丢失。\n4. 丢弃已经提交的更改 如果你已经提交了更改，但想要撤销提交，可以使用以下命令：\n回滚到之前的提交但保留更改在工作区：\n1 git reset --soft \u0026lt;commit-hash\u0026gt; 这将把当前分支重置到指定的提交，但保留更改在暂存区。\n彻底丢弃提交后的更改：\n1 git reset --hard \u0026lt;commit-hash\u0026gt; 这个命令会将当前分支重置到指定的提交，工作区和暂存区的更改都会被丢弃。\n5. 丢弃特定提交的更改 如果你想撤销某个特定的提交，可以使用 git revert：\n1 git revert \u0026lt;commit-hash\u0026gt; 这个命令会生成一个新的提交来撤销指定的更改，而不会影响其他历史提交。\n使用这些命令时需要谨慎，特别是 git reset --hard，因为这会丢失所有未提交的更改，无法恢复。\n","permalink":"http://119.91.218.8/zh/posts/1429/","summary":"\u003ch3 id=\"丢弃更改\"\u003e丢弃更改\u003c/h3\u003e\n\u003ch4 id=\"1-丢弃工作区的未暂存更改\"\u003e1. \u003cstrong\u003e丢弃工作区的未暂存更改\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003e如果你在工作区修改了文件但尚未暂存（使用 \u003ccode\u003egit add\u003c/code\u003e），可以使用以下命令将文件恢复到上一次提交时的状态：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003egit checkout -- \u0026lt;file\u0026gt;\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e这个命令会丢弃指定文件的更改，恢复到上次提交的版本。\u003c/p\u003e","title":"常用git操作"},{"content":"2 背景 我们提供了一些关于现代硬件（GPU）上常见深度学习操作性能特性的背景信息，并描述了注意力机制的标准实现。\n2.1 硬件性能 我们主要关注GPU。其他硬件加速器的性能类似。\nGPU内存层次结构\nGPU的内存层次结构（图1左侧）包含多种不同大小和速度的内存，其中较小的内存速度更快。例如，A100 GPU具有40-80GB的高带宽内存（HBM），其带宽为1.5-2.0TB/s，并且每个108个流处理器（streaming multiprocessors）中的每个都具有192KB的片上SRAM，带宽估计为19TB/s左右。片上SRAM的速度比HBM快一个数量级，但其大小则小了许多数量级。随着计算速度相对于内存速度的提升，操作越来越受到内存（HBM）访问的瓶颈影响。因此，利用快速的SRAM变得更加重要。\n执行模型\nGPU拥有大量线程来执行一个操作（称为kernel）。每个kernel从HBM加载输入到寄存器和SRAM中，进行计算，然后将输出写入HBM。\n性能特性\n根据计算和内存访问的平衡，操作可以分为计算受限或内存受限。这通常通过算术强度来衡量，算术强度是每字节内存访问的算术操作数量。\n计算受限：操作的时间取决于算术操作的数量，而访问HBM的时间则要少得多。典型的例子包括具有大内维度的矩阵乘法和具有大量通道的卷积。\n内存受限：操作的时间取决于内存访问的数量，而计算所花费的时间则要少得多。例子包括大多数其他操作：元素级操作（例如，激活、dropout），以及归约操作（例如，求和、softmax、批量归一化、层归一化）。\n内核融合\n加速内存受限操作的最常见方法是内核融合：如果有多个操作应用于相同的输入，则输入可以从HBM中加载一次，而不是为每个操作多次加载。编译器可以自动融合许多元素级操作。然而，在模型训练的背景下，中间值仍需要写入HBM以供反向传播使用，从而降低了简单内核融合的效果。\n2.2 标准注意力机制实现 给定输入序列 $Q, K, V ∈ R^{N\\times d}$，其中 𝑁 是序列长度，𝑑 是头部维度，我们需要计算注意力输出$O ∈ R^{N\\times d}$: $$ S =QK^T\\in R^{N\\times N},\\quad P=softmax(S)\\in R^{N\\times N},\\quad O=PV\\in R^{N\\times N} $$ 其中 softmax 是按行应用【applied row-wise】的。\n标准的注意力机制实现将矩阵 S 和 P 物化【materialize】到高带宽内存（HBM），这需要 𝑂(𝑁²) 的内存。通常 𝑁 远大于 𝑑（例如，对于 GPT-2，𝑁 = 1024 而 𝑑 = 64）。我们在算法0中描述了标准注意力机制的实现。由于部分或大多数操作都是内存受限的（例如 softmax），大量的内存访问会导致较慢的实际运行时间。\n这个问题因应用于注意力矩阵的其他元素级操作而加剧，例如应用于 S 的掩码操作或应用于 P 的 dropout。因此，已有许多尝试将几个元素级操作融合在一起，例如将掩码与 softmax 融合。\n在第3.2节中，我们将展示标准注意力机制实现中高带宽内存的访问次数是序列长度 𝑁 的平方。同时，我们还将比较标准注意力机制与我们的方法（FlashAttention）的FLOPs数量和高带宽内存访问次数。\n算法0：标准注意力机制实现\n前提条件：HBM中的矩阵 $Q, K, V ∈ R^{N\\times d}$。\n从HBM按块加载 Q 和 K，计算 $S = QKᵀ$，并将 S 写入 HBM。 从HBM读取 S，计算$P = softmax(S)$，并将 P 写入 HBM。 从HBM按块加载 P 和 V，计算 $O = PV$，并将 O 写入 HBM。 返回 O。 3 FlashAttention: 算法、分析与扩展 我们展示了如何在减少HBM读取/写入次数的情况下计算精确的注意力，并且无需为反向传播存储大型中间矩阵。这产生了一种既节省内存又在实际运行时间上更快的注意力算法。我们分析了其IO复杂性，表明我们的方法相比于标准注意力机制需要更少的HBM访问次数。我们进一步展示了FlashAttention作为一个有用的基本模块可以扩展为处理块稀疏注意力。\n为了便于讲解，我们主要关注前向传播部分；附录B包含了反向传播的详细信息。\n3.1 一种使用分块和重计算的高效注意力算法 给定HBM中的输入 $Q, K, V \\in \\mathbb{R}^{N \\times d}$，我们的目标是计算注意力输出 $O \\in \\mathbb{R}^{N \\times d}$ 并将其写入HBM。我们的目标是减少HBM访问次数（到 $N$ 的亚二次方）。\n我们应用了两种已确立的技术（分块、重计算）来克服在 $N$ 的亚二次方HBM访问次数下计算精确注意力的技术挑战。我们在算法1中描述了这一过程。主要思路是将输入 $Q, K, V$ 分块，从慢速HBM加载到快速SRAM，然后根据这些块计算注意力输出。通过在累加之前按正确的归一化因子缩放每个块的输出，我们最终得到正确的结果。\n分块\n我们按块计算注意力。Softmax将 $K$ 的列耦合在一起，因此我们通过缩放来分解大的softmax。为了数值稳定性，向量 $x \\in \\mathbb{R}^B$ 的softmax计算如下： $$ m(x) := \\max_i x_i, \\quad f(x) := \\left[ \\exp(x_1 - m(x)), \\dots, \\exp(x_B - m(x)) \\right], \\quad \\ell(x) := \\sum_i f(x)_i, \\quad \\text{softmax}(x) := \\frac{f(x)}{\\ell(x)} $$ 对于向量 $x^{(1)}, x^{(2)} \\in \\mathbb{R}^B$，我们可以分解连接后的 $x = \\left[ x^{(1)}, x^{(2)} \\right] \\in \\mathbb{R}^{2B}$ 的softmax计算为： $$ m(x) = m\\left(\\left[ x^{(1)}, x^{(2)} \\right]\\right) = \\max\\left(m(x^{(1)}), m(x^{(2)})\\right), \\quad f(x) = \\left[ \\exp(m(x^{(1)}) - m(x)) f(x^{(1)}), \\exp(m(x^{(2)}) - m(x)) f(x^{(2)}) \\right], $$ $$ \\ell(x) = \\ell\\left(\\left[ x^{(1)}, x^{(2)} \\right]\\right) = \\exp(m(x^{(1)}) - m(x)) \\ell(x^{(1)}) + \\exp(m(x^{(2)}) - m(x)) \\ell(x^{(2)}), \\quad \\text{softmax}(x) = \\frac{f(x)}{\\ell(x)} $$ 因此，如果我们跟踪一些额外的统计数据（$m(x), \\ell(x)$），我们可以一次计算一个块的softmax值。我们将输入 $Q, K, V$ 分块（算法1第3行），计算softmax值及额外的统计数据（算法1第10行），并合并结果（算法1第12行）。\n重计算\n我们的目标之一是避免存储 $O(N^2)$ 个用于反向传播的中间值。反向传播通常需要矩阵 $S, P \\in \\mathbb{R}^{N \\times N}$ 来计算相对于 $Q, K, V$ 的梯度。然而，通过存储输出 $O$ 和softmax归一化统计数据（$m, \\ell$），我们可以在反向传播过程中从SRAM中的 $Q, K, V$ 块轻松重计算注意力矩阵 $S$ 和 $P$。这可以视为一种选择性梯度检查点策略。虽然梯度检查点策略已被建议用于减少所需的最大内存量，但所有已知的实现都不得不在速度和内存之间进行权衡。相比之下，即使有更多的FLOPs，我们的重计算由于减少了HBM访问次数而加快了反向传播过程。完整的反向传播描述见附录B。\n实现细节：内核融合\n分块使我们能够在一个CUDA内核中实现我们的算法，从HBM加载输入，执行所有计算步骤（矩阵乘法、softmax、可选的掩码和dropout、矩阵乘法），然后将结果写回HBM（掩码和dropout在附录B中）。这避免了反复从HBM读取和写入输入和输出。\n算法1：FlashAttention\n前提条件：HBM中的矩阵 $Q, K, V \\in \\mathbb{R}^{N \\times d}$，片上SRAM大小为 $M$。\n设置块大小 $B_c = \\left\\lceil \\frac{M}{4d} \\right\\rceil$, $B_r = min ( \\lceil \\frac{M}{4d} \\rceil ,d)$. 初始化 $O = (0)_{N \\times d} \\in \\mathbb{R}^{N \\times d}$, $\\ell = (0)_N \\in \\mathbb{R}^N$, $m = (-\\infty)_N \\in \\mathbb{R}^N$ 在HBM中。 将 $Q$ 分成 $T_r = \\left\\lceil \\frac{N}{B_r} \\right\\rceil$ 个块 $Q_1, \\dots, Q_{T_r}$ ，每个大小为 $B_r \\times d$；将 $K, V$ 分成 $T_c = \\left\\lceil \\frac{N}{B_c} \\right\\rceil$ 个块 $K_1, \\dots, K_{T_c}$ 和 $V_1, \\dots, V_{T_c}$ ，每个大小为 $B_c \\times d$。 将 $O$ 分成 $T_r$ 个块 $O_i, \\dots, O_{T_r}$ ，每个大小为 $B_r \\times d$；将 $\\ell$ 分成 $T_r$ 个块 $\\ell_i, \\dots, \\ell_{T_r}$ ，每个大小为 $B_r$；将 $m$ 分成 $T_r$ 个块 $m_1, \\dots, m_{T_r}$ ，每个大小为 $B_r$。 对于 $1 \\leq j \\leq T_c$： 从HBM加载 $K_j, V_j$ 到片上SRAM。 对于 $1 \\leq i \\leq T_r$： 从HBM加载 $Q_i, O_i, \\ell_i, m_i$ 到片上SRAM。 在片上计算 $S_{ij} = Q_i K_j^\\top \\in \\mathbb{R}^{B_r \\times B_c}$。 在片上计算 $\\tilde{m}{ij} = \\text{rowmax}(S{ij}) \\in \\mathbb{R}^{B_r}$，$\\tilde{P}{ij} = \\exp(S{ij} - \\tilde{m}{ij}) \\in \\mathbb{R}^{B_r \\times B_c}$（逐点计算），$\\tilde{\\ell}{ij} = \\text{rowsum}(\\tilde{P}_{ij}) \\in \\mathbb{R}^{B_r}$。 在片上计算 $m_{i}^{\\text{new}} = \\max(m_i, \\tilde{m}{ij}) \\in \\mathbb{R}^{B_r}$，$\\ell{i}^{\\text{new}} = \\exp(m_i - m_{i}^{\\text{new}})\\ell_i + \\exp(\\tilde{m}{ij} - m{i}^{\\text{new}})\\tilde{\\ell}_{ij} \\in \\mathbb{R}^{B_r}$。 写入$$O_i \\leftarrow \\text{diag}(\\ell_{i}^{\\text{new}})^{-1}\\left(\\text{diag}(\\ell_i)\\exp(m_i-m {i}^{\\text{new}})O_i + \\exp(\\tilde{m}{ij} - m_{i}^{\\text{new}})\\tilde{P}_{ij}V_j\\right)$$ 到HBM。 写入 $\\ell_i \\leftarrow \\ell_{i}^{\\text{new}}$，$m_i \\leftarrow m_{i}^{\\text{new}}$ 到HBM。 结束循环 结束循环 返回 $O$。 我们证明了FlashAttention的正确性、运行时间和内存需求（证明在附录C中）。\n定理1：算法1返回 $O = \\text{softmax}(QK^\\top)V$ ，具有 $\\mathcal{O}(N^2d)$ 的FLOPs，并且除了输入和输出之外仅需要 $\\mathcal{O}(N)$ 的额外内存。\n","permalink":"http://119.91.218.8/zh/posts/1647/","summary":"\u003ch2 id=\"2-背景\"\u003e2 背景\u003c/h2\u003e\n\u003cp\u003e我们提供了一些关于现代硬件（GPU）上常见深度学习操作性能特性的背景信息，并描述了注意力机制的标准实现。\u003c/p\u003e\n\u003ch3 id=\"21-硬件性能\"\u003e2.1 硬件性能\u003c/h3\u003e\n\u003cp\u003e我们主要关注GPU。其他硬件加速器的性能类似。\u003c/p\u003e","title":"FlashAttention Fast and Memory-Efficient Exact Attention with IO-Awareness"}]